{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting transformers[sentencepiece]\n",
      "  Using cached transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from datasets) (1.24.1)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Using cached pyarrow-13.0.0-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.1.1-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Collecting tqdm>=4.62.1 (from datasets)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.4.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.8.6-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from datasets) (23.2)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Collecting regex!=2019.12.17 (from transformers[sentencepiece])\n",
      "  Using cached regex-2023.10.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers[sentencepiece])\n",
      "  Using cached tokenizers-0.14.1-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers[sentencepiece])\n",
      "  Using cached safetensors-0.4.0-cp311-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "Collecting protobuf (from transformers[sentencepiece])\n",
      "  Using cached protobuf-4.24.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: psutil in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from peft) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from peft) (2.1.0+cu118)\n",
      "Collecting accelerate (from peft)\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.4.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: sympy in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from torch>=1.13.0->peft) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\carlos\\documents\\git\\llms\\.env\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Using cached datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.6/85.6 kB 4.7 MB/s eta 0:00:00\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Using cached aiohttp-3.8.6-cp311-cp311-win_amd64.whl (322 kB)\n",
      "Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Using cached pyarrow-13.0.0-cp311-cp311-win_amd64.whl (24.3 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "Using cached regex-2023.10.3-cp311-cp311-win_amd64.whl (269 kB)\n",
      "Using cached safetensors-0.4.0-cp311-none-win_amd64.whl (277 kB)\n",
      "Using cached tokenizers-0.14.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 258.1/258.1 kB 16.5 MB/s eta 0:00:00\n",
      "Using cached multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "Using cached pandas-2.1.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Using cached protobuf-4.24.4-cp310-abi3-win_amd64.whl (430 kB)\n",
      "Using cached transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached frozenlist-1.4.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Installing collected packages: sentencepiece, pytz, xxhash, tzdata, tqdm, safetensors, regex, pyyaml, pyarrow, protobuf, multidict, frozenlist, dill, attrs, async-timeout, yarl, responses, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, accelerate, transformers, peft, datasets, evaluate\n",
      "Successfully installed accelerate-0.23.0 aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 datasets-2.14.5 dill-0.3.7 evaluate-0.4.1 frozenlist-1.4.0 huggingface-hub-0.17.3 multidict-6.0.4 multiprocess-0.70.15 pandas-2.1.1 peft-0.5.0 protobuf-4.24.4 pyarrow-13.0.0 pytz-2023.3.post1 pyyaml-6.0.1 regex-2023.10.3 responses-0.18.0 safetensors-0.4.0 sentencepiece-0.1.99 tokenizers-0.14.1 tqdm-4.66.1 transformers-4.34.1 tzdata-2023.3 xxhash-3.4.1 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece] peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\"\n",
    "base_model = \"meta-llama/Llama-2-7b-hf\"\n",
    "peft_model = \"FinGPT/fingpt-mt_llama2-7b_lora\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, device_map=device)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, peft_model)\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. \n",
      "For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "instruction = \"What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\"\n",
    "news = \"For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m\" \n",
    "\n",
    "instruction = f\"{instruction} \\n{news} \\nAnswer:\"\n",
    "print(instruction)\n",
    "\n",
    "model_input = tokenizer(instruction, return_tensors=\"pt\")\n",
    "model_input = model_input.to(device)\n",
    "\n",
    "res = model.generate(**model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. \\nFor the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m \\nAnswer: No</s>\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sentences = [tokenizer.decode(i) for i in res]\n",
    "res_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
