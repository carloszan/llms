{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "base_model = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, device_map=\"auto\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model, load_in_8bit=True, torch_dtype=torch.float16)\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt example:\n",
      "@gakrum nice chart shows distinctive down channel not a dip.. where do you see the bottom? $SPY ..$150? ..$130?\n",
      "\n",
      "\n",
      "Total len: 150. Batchsize: 8. Total steps: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.41333333333333333. F1 macro: 0.3131468088733046. F1 micro: 0.41333333333333333. F1 weighted (BloombergGPT): 0.3131468088733046. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>out_text</th>\n",
       "      <th>new_out_np</th>\n",
       "      <th>new_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$HCP Come to the party and buy this -gonna giv...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4479206, 0.5520794]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@gakrum nice chart shows distinctive down chan...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.980034, 0.019966036]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan's Asahi to submit bid next week for SABM...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9754836, 0.024516335]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tesla Motors recalls 2,700 Model X SUVs $TSLA ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.99649614, 0.003503823]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRH's concrete bid for Holcim Lafarge assets</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.98498523, 0.015014747]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Intertek swings to ÃÂ£347 mln loss on oil's s...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.99939764, 0.0006023541]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>RT @jan $ARNA Don't think buyout rumor strong ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.98866826, 0.011331754]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Barclays appoints JPMorgan's Paul Compton as n...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.008140463, 0.9918595]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>$AAPL Now I'm glad I got stopped out of my $11...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.99687636, 0.0031236487]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Tullow Oil Suspends Dividend Amid Oil Price Fall</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.9978719, 0.00212811]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  target  \\\n",
       "0    $HCP Come to the party and buy this -gonna giv...       0   \n",
       "1    @gakrum nice chart shows distinctive down chan...       2   \n",
       "2    Japan's Asahi to submit bid next week for SABM...       0   \n",
       "3    Tesla Motors recalls 2,700 Model X SUVs $TSLA ...       2   \n",
       "4         CRH's concrete bid for Holcim Lafarge assets       0   \n",
       "..                                                 ...     ...   \n",
       "145  Intertek swings to ÃÂ£347 mln loss on oil's s...       2   \n",
       "146  RT @jan $ARNA Don't think buyout rumor strong ...       1   \n",
       "147  Barclays appoints JPMorgan's Paul Compton as n...       1   \n",
       "148  $AAPL Now I'm glad I got stopped out of my $11...       1   \n",
       "149   Tullow Oil Suspends Dividend Amid Oil Price Fall       2   \n",
       "\n",
       "                       out_text  new_out_np  new_out  \n",
       "0        [0.4479206, 0.5520794]           1        0  \n",
       "1       [0.980034, 0.019966036]           0        2  \n",
       "2      [0.9754836, 0.024516335]           0        2  \n",
       "3     [0.99649614, 0.003503823]           0        2  \n",
       "4     [0.98498523, 0.015014747]           0        2  \n",
       "..                          ...         ...      ...  \n",
       "145  [0.99939764, 0.0006023541]           0        2  \n",
       "146   [0.98866826, 0.011331754]           0        2  \n",
       "147    [0.008140463, 0.9918595]           1        0  \n",
       "148  [0.99687636, 0.0031236487]           0        2  \n",
       "149     [0.9978719, 0.00212811]           0        2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def change_format(x):\n",
    "    dic = {0:2, 1:0}\n",
    "    return dic[x]\n",
    "\n",
    "def test_fiqa(model, tokenizer, batch_size=8):\n",
    "    dataset = load_dataset('pauri32/fiqa-2018')\n",
    "    dataset = dataset[\"test\"]\n",
    "    dataset = dataset.to_pandas()\n",
    "\n",
    "    dataset[\"target\"] = dataset['label']\n",
    "\n",
    "    dataset = dataset[['sentence', 'target']]\n",
    "    dataset.columns = ['input', 'target']\n",
    "\n",
    "    # print example\n",
    "    print(f\"\\n\\nPrompt example:\\n{dataset['input'][1]}\\n\\n\")\n",
    "\n",
    "    context = dataset['input'].tolist()\n",
    "    total_steps = dataset.shape[0]//batch_size + 1\n",
    "    print(\n",
    "        f\"Total len: {len(context)}. Batchsize: {batch_size}. Total steps: {total_steps}\")\n",
    "\n",
    "    out_text = []\n",
    "\n",
    "    for i in tqdm(range(total_steps)):\n",
    "        tmp_context = context[i * batch_size:(i+1) * batch_size]\n",
    "\n",
    "        tokenizer.pad_token = \"[PAD]\"\n",
    "\n",
    "        tokens = tokenizer(tmp_context, return_tensors='pt', padding=True)\n",
    "\n",
    "        output = model(**tokens)\n",
    "        output = torch.nn.functional.softmax(output.logits.float(), dim=-1)\n",
    "        out_text.append(output.detach().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    out_text = [item for sublist in out_text for item in sublist]\n",
    "    dataset[\"out_text\"] = out_text\n",
    "    dataset[\"new_out_np\"] = dataset[\"out_text\"].apply(np.argmax)\n",
    "    dataset[\"new_out\"] = dataset[\"new_out_np\"].apply(change_format)\n",
    "\n",
    "    acc = accuracy_score(dataset[\"target\"], dataset[\"new_out\"])\n",
    "    f1_macro = f1_score(dataset[\"target\"], dataset[\"new_out\"], average=\"macro\")\n",
    "    f1_micro = f1_score(dataset[\"target\"], dataset[\"new_out\"], average=\"micro\")\n",
    "    f1_weighted = f1_score(\n",
    "        dataset[\"target\"], dataset[\"new_out\"], average=\"weighted\")\n",
    "\n",
    "    print(f\"Acc: {acc}. F1 macro: {f1_macro}. F1 micro: {f1_micro}. F1 weighted (BloombergGPT): {f1_weighted}. \")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = test_fiqa(model, tokenizer)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../results/distilbert-base-uncased-finetuned-sst-2-english-no-neutral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.query(\"target == 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove neutral label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt example:\n",
      "@gakrum nice chart shows distinctive down channel not a dip.. where do you see the bottom? $SPY ..$150? ..$130?\n",
      "\n",
      "\n",
      "Total len: 100. Batchsize: 8. Total steps: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 36.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.63. F1 macro: 0.5960257670051317. F1 micro: 0.63. F1 weighted (BloombergGPT): 0.5960257670051317. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>out_text</th>\n",
       "      <th>new_out_np</th>\n",
       "      <th>new_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$HCP Come to the party and buy this -gonna give solid gains and a dividend $$$$$$</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4479206, 0.5520794]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@gakrum nice chart shows distinctive down channel not a dip.. where do you see the bottom? $SPY ..$150? ..$130?</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.980034, 0.019966036]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan's Asahi to submit bid next week for SABMiller's Grolsch and Peroni - Yomiuri</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9754836, 0.024516335]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tesla Motors recalls 2,700 Model X SUVs $TSLA https://t.co/F55dx4aegI</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.99649614, 0.003503823]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRH's concrete bid for Holcim Lafarge assets</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.98498523, 0.015014747]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>FDA Approves AstraZeneca's Iressa As Lung Cancer Treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8407172, 0.15928277]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>energy still failing to close above the 10D MA.  continues to stand out weak $XLE</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.999757, 0.00024298552]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>AstraZeneca's patent on asthma drug invalidated by US court</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.9983026, 0.0016974094]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Intertek swings to ÃÂ£347 mln loss on oil's slump</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.99936503, 0.00063495064]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Tullow Oil Suspends Dividend Amid Oil Price Fall</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.99782157, 0.0021784669]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               input  \\\n",
       "0                                  $HCP Come to the party and buy this -gonna give solid gains and a dividend $$$$$$   \n",
       "1    @gakrum nice chart shows distinctive down channel not a dip.. where do you see the bottom? $SPY ..$150? ..$130?   \n",
       "2                                 Japan's Asahi to submit bid next week for SABMiller's Grolsch and Peroni - Yomiuri   \n",
       "3                                              Tesla Motors recalls 2,700 Model X SUVs $TSLA https://t.co/F55dx4aegI   \n",
       "4                                                                       CRH's concrete bid for Holcim Lafarge assets   \n",
       "..                                                                                                               ...   \n",
       "141                                                       FDA Approves AstraZeneca's Iressa As Lung Cancer Treatment   \n",
       "142                                energy still failing to close above the 10D MA.  continues to stand out weak $XLE   \n",
       "143                                                      AstraZeneca's patent on asthma drug invalidated by US court   \n",
       "145                                                               Intertek swings to ÃÂ£347 mln loss on oil's slump   \n",
       "149                                                                 Tullow Oil Suspends Dividend Amid Oil Price Fall   \n",
       "\n",
       "     target                     out_text  new_out_np  new_out  \n",
       "0         0       [0.4479206, 0.5520794]           1        0  \n",
       "1         2      [0.980034, 0.019966036]           0        2  \n",
       "2         0     [0.9754836, 0.024516335]           0        2  \n",
       "3         2    [0.99649614, 0.003503823]           0        2  \n",
       "4         0    [0.98498523, 0.015014747]           0        2  \n",
       "..      ...                          ...         ...      ...  \n",
       "141       0      [0.8407172, 0.15928277]           0        2  \n",
       "142       2    [0.999757, 0.00024298552]           0        2  \n",
       "143       2    [0.9983026, 0.0016974094]           0        2  \n",
       "145       2  [0.99936503, 0.00063495064]           0        2  \n",
       "149       2   [0.99782157, 0.0021784669]           0        2  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def change_format(x):\n",
    "    dic = {0:2, 1:0}\n",
    "    return dic[x]\n",
    "\n",
    "def test_fiqa(model, tokenizer, batch_size=8):\n",
    "    dataset = load_dataset('pauri32/fiqa-2018')\n",
    "    dataset = dataset[\"test\"]\n",
    "    dataset = dataset.to_pandas()\n",
    "\n",
    "    dataset[\"target\"] = dataset['label']\n",
    "    dataset = dataset[dataset[\"target\"] != 1]\n",
    "\n",
    "    dataset = dataset[['sentence', 'target']]\n",
    "    dataset.columns = ['input', 'target']\n",
    "\n",
    "    # print example\n",
    "    print(f\"\\n\\nPrompt example:\\n{dataset['input'][1]}\\n\\n\")\n",
    "\n",
    "    context = dataset['input'].tolist()\n",
    "    total_steps = dataset.shape[0]//batch_size + 1\n",
    "    print(\n",
    "        f\"Total len: {len(context)}. Batchsize: {batch_size}. Total steps: {total_steps}\")\n",
    "\n",
    "    out_text = []\n",
    "\n",
    "    for i in tqdm(range(total_steps)):\n",
    "        tmp_context = context[i * batch_size:(i+1) * batch_size]\n",
    "\n",
    "        tokenizer.pad_token = \"[PAD]\"\n",
    "\n",
    "        tokens = tokenizer(tmp_context, return_tensors='pt', padding=True)\n",
    "\n",
    "        output = model(**tokens)\n",
    "        output = torch.nn.functional.softmax(output.logits.float(), dim=-1)\n",
    "        out_text.append(output.detach().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    out_text = [item for sublist in out_text for item in sublist]\n",
    "    dataset[\"out_text\"] = out_text\n",
    "    dataset[\"new_out_np\"] = dataset[\"out_text\"].apply(np.argmax)\n",
    "    dataset[\"new_out\"] = dataset[\"new_out_np\"].apply(change_format)\n",
    "\n",
    "    acc = accuracy_score(dataset[\"target\"], dataset[\"new_out\"])\n",
    "    f1_macro = f1_score(dataset[\"target\"], dataset[\"new_out\"], average=\"macro\")\n",
    "    f1_micro = f1_score(dataset[\"target\"], dataset[\"new_out\"], average=\"micro\")\n",
    "    f1_weighted = f1_score(\n",
    "        dataset[\"target\"], dataset[\"new_out\"], average=\"weighted\")\n",
    "\n",
    "    print(f\"Acc: {acc}. F1 macro: {f1_macro}. F1 micro: {f1_micro}. F1 weighted (BloombergGPT): {f1_weighted}. \")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = test_fiqa(model, tokenizer)\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
